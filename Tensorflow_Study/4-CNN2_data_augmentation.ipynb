{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPa3KZujankMnTFL+q0Joh6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["### Data Augmentation makes underfit but best for overfitting"],"metadata":{"id":"74ikfIxRuJKW","executionInfo":{"status":"ok","timestamp":1696542150425,"user_tz":-180,"elapsed":257,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LaldRkvhuArU","executionInfo":{"status":"ok","timestamp":1696542150701,"user_tz":-180,"elapsed":3,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}}},"outputs":[],"source":["import os\n","import zipfile\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["# Download the dataset\n","!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqzTn7hJx0VK","executionInfo":{"status":"ok","timestamp":1696542151317,"user_tz":-180,"elapsed":618,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}},"outputId":"67b92fb1-3003-40be-f236-bb2fd2936d04"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-05 21:42:30--  https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.213.207, 142.251.162.207, 173.194.215.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.213.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 68606236 (65M) [application/zip]\n","Saving to: ‘cats_and_dogs_filtered.zip.1’\n","\n","cats_and_dogs_filte 100%[===================>]  65.43M   173MB/s    in 0.4s    \n","\n","2023-10-05 21:42:31 (173 MB/s) - ‘cats_and_dogs_filtered.zip.1’ saved [68606236/68606236]\n","\n"]}]},{"cell_type":"code","source":["# Extract the archive\n","zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n","zip_ref.extractall(\"tmp/\")\n","zip_ref.close()\n","\n","# Assign training and validation set directories\n","base_dir = 'tmp/cats_and_dogs_filtered'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","\n","# Directory with training cat pictures\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","\n","# Directory with training dog pictures\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","\n","# Directory with validation cat pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","\n","# Directory with validation dog pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')"],"metadata":{"id":"onQoV26hx2O5","executionInfo":{"status":"ok","timestamp":1696542152638,"user_tz":-180,"elapsed":1323,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# This code has changed. Now instead of the ImageGenerator just rescaling\n","# the image, we also rotate and do other operations\n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=20,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywoszSi7x3pR","executionInfo":{"status":"ok","timestamp":1696542152639,"user_tz":-180,"elapsed":5,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}},"outputId":"6aa6e4f2-f81c-40bd-d1c1-f86e338f3f17"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["model_1 = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(filters = 16, kernel_size = (3,3), activation = \"relu\", input_shape = (150, 150, 3)),\n","    tf.keras.layers.MaxPool2D(2,2),\n","    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = \"relu\"),\n","    tf.keras.layers.MaxPool2D(2,2),\n","    tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\"),\n","    tf.keras.layers.MaxPool2D(2,2),\n","    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\"),\n","    tf.keras.layers.MaxPool2D(2,2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation = \"relu\"),\n","    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n","    ]\n",")\n","\n","model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n","                optimizer = tf.keras.optimizers.Adam(),\n","                metrics = [\"accuracy\"])\n","\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if logs.get('val_accuracy') is not None and logs.get('val_accuracy') > 0.70:\n","            print(\"\\nReached 70% val accuracy so cancelling training!\")\n","            self.model.stop_training = True"],"metadata":{"id":"RGtge_dayBTh","executionInfo":{"status":"ok","timestamp":1696542153830,"user_tz":-180,"elapsed":1194,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["history_1 = model_1.fit(train_generator,\n","                        epochs = 100,\n","                        validation_data=validation_generator,\n","                        callbacks = [myCallback()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okD-YsOMyHJB","executionInfo":{"status":"ok","timestamp":1696543014694,"user_tz":-180,"elapsed":831963,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}},"outputId":"b29b3ec8-d1d4-4572-f24b-7c5336ca2a00"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","100/100 [==============================] - 75s 728ms/step - loss: 0.6983 - accuracy: 0.5035 - val_loss: 0.6933 - val_accuracy: 0.5030\n","Epoch 2/100\n","100/100 [==============================] - 69s 693ms/step - loss: 0.6841 - accuracy: 0.5625 - val_loss: 0.6856 - val_accuracy: 0.5000\n","Epoch 3/100\n","100/100 [==============================] - 67s 668ms/step - loss: 0.6677 - accuracy: 0.5835 - val_loss: 0.6339 - val_accuracy: 0.6570\n","Epoch 4/100\n","100/100 [==============================] - 67s 671ms/step - loss: 0.6634 - accuracy: 0.6120 - val_loss: 0.6379 - val_accuracy: 0.6660\n","Epoch 5/100\n","100/100 [==============================] - 67s 671ms/step - loss: 0.6397 - accuracy: 0.6145 - val_loss: 0.6277 - val_accuracy: 0.6540\n","Epoch 6/100\n","100/100 [==============================] - 66s 664ms/step - loss: 0.6301 - accuracy: 0.6450 - val_loss: 0.6354 - val_accuracy: 0.6190\n","Epoch 7/100\n","100/100 [==============================] - 68s 683ms/step - loss: 0.6297 - accuracy: 0.6490 - val_loss: 0.5789 - val_accuracy: 0.6940\n","Epoch 8/100\n","100/100 [==============================] - 69s 687ms/step - loss: 0.5997 - accuracy: 0.6820 - val_loss: 0.5988 - val_accuracy: 0.6670\n","Epoch 9/100\n","100/100 [==============================] - 67s 670ms/step - loss: 0.6081 - accuracy: 0.6785 - val_loss: 0.5998 - val_accuracy: 0.6890\n","Epoch 10/100\n","100/100 [==============================] - 65s 649ms/step - loss: 0.5936 - accuracy: 0.6825 - val_loss: 0.5766 - val_accuracy: 0.6870\n","Epoch 11/100\n","100/100 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.6995\n","Reached 70% val accuracy so cancelling training!\n","100/100 [==============================] - 68s 676ms/step - loss: 0.5892 - accuracy: 0.6995 - val_loss: 0.5681 - val_accuracy: 0.7150\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yUc_A2CKyiTq","executionInfo":{"status":"aborted","timestamp":1696542153832,"user_tz":-180,"elapsed":6,"user":{"displayName":"Sinan Cavusoglu","userId":"06975447756133709697"}}},"execution_count":null,"outputs":[]}]}